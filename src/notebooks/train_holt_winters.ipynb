{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9cadbfcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from src.holt_winters import create_holt_winters_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e5ae5366",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (87015, 1)\n",
            "Total entries in dataset: 87015\n",
            "Date range: 1995-07-01 00:00:00 - 1995-08-31 23:59:00\n",
            "First 5 rows: \n",
            "                      number_of_requests\n",
            "time                                   \n",
            "1995-07-01 00:00:00                  42\n",
            "1995-07-01 00:01:00                  61\n",
            "1995-07-01 00:02:00                  57\n",
            "1995-07-01 00:03:00                  71\n",
            "1995-07-01 00:04:00                  70\n"
          ]
        }
      ],
      "source": [
        "# Import and visualise dataset\n",
        "df = pd.read_csv(\"datasets/nasa_requests_per_minute.csv\")\n",
        "df['time'] = pd.to_datetime(df['time'])\n",
        "df = df.set_index('time')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Total entries in dataset: {len(df)}\")\n",
        "print(f\"Date range: {df.index.min()} - {df.index.max()}\")\n",
        "print(f\"First 5 rows: \\n {df.head()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9b85c4b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data: 69612 entries\n",
            "Date range: 1995-07-01 00:00:00 - 1995-08-19 21:56:00 \n",
            "\n",
            "Test data: 17403 entries\n",
            "Date range: 1995-08-19 21:57:00 - 1995-08-31 23:59:00\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into train and test sets at 80/20 ratio\n",
        "train_size = int(len(df) * 0.8)\n",
        "\n",
        "train_dataset = df.iloc[:train_size]\n",
        "test_dataset = df.iloc[train_size:]\n",
        "\n",
        "print(f\"Train data: {len(train_dataset)} entries\")\n",
        "print(f\"Date range: {train_dataset.index.min()} - {train_dataset.index.max()} \\n\")\n",
        "print(f\"Test data: {len(test_dataset)} entries\")\n",
        "print(f\"Date range: {test_dataset.index.min()} - {test_dataset.index.max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e7e93d81",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ajaylk\\uni\\fyp\\code\\tsf-models\\venv\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:903: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training complete! \n",
            " Model fitted: True\n"
          ]
        }
      ],
      "source": [
        "# Create and train model\n",
        "holt_winters_model = create_holt_winters_model(seasonal_periods=1440)\n",
        "\n",
        "print(\"Training model...\")\n",
        "holt_winters_model.fit(train_dataset['number_of_requests'].tolist())\n",
        "print(f\"Model training complete! \\n Model fitted: {holt_winters_model.is_fitted()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f20d30e4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'src.holt_winters' from 'C:\\\\Users\\\\ajaylk\\\\uni\\\\fyp\\\\code\\\\tsf-models\\\\src\\\\holt_winters.py'>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "import src.holt_winters\n",
        "importlib.reload(src.holt_winters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3d4deadd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running model against test data...\n",
            "Processed 1000/17403 test samples\n",
            "Processed 2000/17403 test samples\n",
            "Processed 3000/17403 test samples\n",
            "Processed 4000/17403 test samples\n",
            "Processed 5000/17403 test samples\n",
            "Processed 6000/17403 test samples\n",
            "Processed 7000/17403 test samples\n",
            "Processed 8000/17403 test samples\n",
            "Processed 9000/17403 test samples\n",
            "Processed 10000/17403 test samples\n",
            "Processed 11000/17403 test samples\n",
            "Processed 12000/17403 test samples\n",
            "Processed 13000/17403 test samples\n",
            "Processed 14000/17403 test samples\n",
            "Processed 15000/17403 test samples\n",
            "Processed 16000/17403 test samples\n",
            "Processed 17000/17403 test samples\n"
          ]
        }
      ],
      "source": [
        "# Test fitted model\n",
        "predictions = []\n",
        "actual_values = []\n",
        "prediction_intervals = []\n",
        "\n",
        "print(\"Running model against test data...\")\n",
        "for i in range(len(test_dataset)):\n",
        "    prediction = holt_winters_model.predict(steps=1)\n",
        "    actual = test_dataset.iloc[i]['number_of_requests']\n",
        "\n",
        "    predictions.append(prediction['prediction'])\n",
        "    actual_values.append(actual)\n",
        "    prediction_intervals.append(\n",
        "        {\n",
        "            'lower_bound': prediction['lower_bound'],\n",
        "            'upper_bound': prediction['upper_bound'],\n",
        "            'std': prediction['std']\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Append actual number of requests\n",
        "    holt_winters_model.update([actual])\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"Processed {i + 1}/{len(test_dataset)} test samples\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da496032",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "path_to_save = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a9096a63",
      "metadata": {},
      "outputs": [],
      "source": [
        "cleaned_predictions = []\n",
        "for prediction in predictions:\n",
        "    cleaned_predictions.append(prediction['mean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4e23b434",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL PERFORMANCE METRICS\n",
            "============================================================\n",
            "Mean Absolute Error (MAE):           10.96 requests\n",
            "Root Mean Squared Error (RMSE):      14.44 requests\n",
            "Prediction Interval Coverage (95%):  93.27%\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Evaluation metrics\n",
        "predictions = np.array(cleaned_predictions)\n",
        "actual_values = np.array(actual_values)\n",
        "\n",
        "mae = mean_absolute_error(actual_values, predictions)\n",
        "mse = mean_squared_error(actual_values, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Calculate % of actual requests within prediction intervals\n",
        "actuals_within_interval = sum(\n",
        "    1 for i, value in enumerate(actual_values) if prediction_intervals[i]['lower_bound'] <= value <= prediction_intervals[i]['upper_bound']\n",
        ") \n",
        "coverage_percentage = (actuals_within_interval / len(actual_values)) * 100\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL PERFORMANCE METRICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Mean Absolute Error (MAE):           {mae:.2f} requests\")\n",
        "print(f\"Root Mean Squared Error (RMSE):      {rmse:.2f} requests\")\n",
        "print(f\"Prediction Interval Coverage (95%):  {coverage_percentage:.2f}%\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f64f55e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debug actual requests vs predicted request values\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Timestamp': test_dataset.index,\n",
        "    'Actual': actual_values,\n",
        "    'Predicted': [round(p, 2) for p in predictions],\n",
        "    'Error': [round(a - p, 2) for a, p in zip(actual_values, predictions)],\n",
        "    'Abs_Error': [round(abs(a - p), 2) for a, p in zip(actual_values, predictions)],\n",
        "    'Lower_95%': [round(pi['lower_bound'], 2) for pi in prediction_intervals],\n",
        "    'Upper_95%': [round(pi['upper_bound'], 2) for pi in prediction_intervals]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"PREDICTION vs ACTUAL COMPARISON (First 50 samples)\")\n",
        "print(\"=\"*100)\n",
        "print(comparison_df.head(50).to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"PREDICTION vs ACTUAL COMPARISON (Last 50 samples)\")\n",
        "print(\"=\"*100)\n",
        "print(comparison_df.tail(50).to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
